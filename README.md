# DeepXY ğŸš€

DeepXY æ˜¯ä¸€ä¸ªåˆ›æ–°çš„ AI å¯¹è¯ç³»ç»Ÿï¼Œç»“åˆäº† DeepSeek çš„å¼ºå¤§æ¨ç†èƒ½åŠ›å’Œå…¶ä»–æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚

## ç‰¹ç‚¹ âœ¨

- ğŸ’¡ **åŒæ¨¡å‹åä½œ**: ç»“åˆ DeepSeek çš„æ¨ç†èƒ½åŠ›å’Œ Qwen çš„ç”Ÿæˆèƒ½åŠ›
- ğŸŒŠ **æµå¼è¾“å‡º**: æ”¯æŒå®æ—¶æµå¼å“åº”
- ğŸ”Œ **OpenAI å…¼å®¹**: å®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼
- ğŸ¯ **é«˜æ€§èƒ½**: ä¼˜åŒ–çš„å¹¶å‘å¤„ç†å’Œé”™è¯¯é‡è¯•æœºåˆ¶
- ğŸ“ **è¯¦ç»†æ—¥å¿—**: ç»“æ„åŒ–çš„æ—¥å¿—è®°å½•ç³»ç»Ÿ

## å¿«é€Ÿå¼€å§‹ ğŸš€

### Docker éƒ¨ç½²

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/StarlitSKy88/deepXY.git
cd deepXY

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å†™å¿…è¦çš„é…ç½®

# å¯åŠ¨æœåŠ¡
docker-compose up -d
```

### æœ¬åœ°å¼€å‘

```bash
# å®‰è£…ä¾èµ–
uv sync

# å¯åŠ¨æœåŠ¡
uvicorn app.main:app --reload
```

## æ”¯æŒçš„æ¨¡å‹ ğŸ“š

- DeepSeek R1
- é€šä¹‰åƒé—® 2.5
- Google Gemini 2.0 Pro
- Anthropic Claude 3 Sonnet
- Meta Llama 2
- Mistral Large

## API ä½¿ç”¨ç¤ºä¾‹ ğŸ’»

```python
import requests

response = requests.post(
    "http://localhost:8000/v1/chat/completions",
    headers={
        "Authorization": "Bearer your-api-key",
        "Content-Type": "application/json"
    },
    json={
        "model": "deepxy",
        "messages": [{"role": "user", "content": "ä½ å¥½"}],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

## é…ç½®è¯´æ˜ âš™ï¸

ä¸»è¦é…ç½®é¡¹ï¼ˆåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ï¼‰ï¼š

```bash
# API è®¤è¯é…ç½®
ALLOW_API_KEY=your-api-key
ALLOW_ORIGINS=*

# æ¨¡å‹é…ç½®
DEEPSEEK_MODEL=deepseek-r1
QWEN_MODEL=qwen2.5-14b-instruct-1m

# æ¨ç†é…ç½®
IS_ORIGIN_REASONING=True

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
```

## å¼€å‘è®¡åˆ’ ğŸ“…

- [ ] æ·»åŠ æ›´å¤šæ¨¡å‹æ”¯æŒ
- [ ] ä¼˜åŒ–å¹¶å‘æ€§èƒ½
- [ ] æ·»åŠ  WebSocket æ”¯æŒ
- [ ] å®Œå–„ç›‘æ§ç³»ç»Ÿ
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•

## è´¡çŒ®æŒ‡å— ğŸ¤

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯ ğŸ“„

[MIT License](LICENSE)